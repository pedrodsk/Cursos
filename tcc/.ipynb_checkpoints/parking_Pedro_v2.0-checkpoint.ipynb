{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e2ee5d",
   "metadata": {},
   "source": [
    "# Apêndice A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab4a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760f4f7",
   "metadata": {},
   "source": [
    "## Importações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9705d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpu = tf.test.gpu_device_name()\n",
    "if gpu == '':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b28551",
   "metadata": {},
   "source": [
    "## Treinar/Carregar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 1 #treinar modelo\n",
    "flag = 0 #carregar modelo !! (Comente para treinar e salvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d83b70",
   "metadata": {},
   "source": [
    "## Configurações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaffa16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (160,160,3)\n",
    "batch = 32\n",
    "\n",
    "vagas = 40\n",
    "pontos = vagas*4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429b4b8",
   "metadata": {},
   "source": [
    "## Importação do Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90966ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = ['../..','datasets']\n",
    "DATASET_DIR=['PKLot','UFPR05']\n",
    "\n",
    "DATASET_DIR = os.path.join(BASE_PATH[0],BASE_PATH[1],\n",
    "                           DATASET_DIR[0],DATASET_DIR[1])\n",
    "DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48f2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = os.path.join(DATASET_DIR,'todas')\n",
    "XML_DIR = IMAGE_DIR\n",
    "\n",
    "\n",
    "IMAGE_LIST = []\n",
    "XML_LIST = []\n",
    "def criarLista():\n",
    "    for file in os.listdir(IMAGE_DIR):\n",
    "        if file.endswith(\".jpg\"):\n",
    "\n",
    "            file = os.path.join(IMAGE_DIR,file)\n",
    "            IMAGE_LIST.append(file)\n",
    "    IMAGE_LIST.sort()\n",
    "\n",
    "    for file in os.listdir(IMAGE_DIR):\n",
    "        if file.endswith(\".xml\"):\n",
    "\n",
    "            file = os.path.join(XML_DIR,file)\n",
    "            XML_LIST.append(file)\n",
    "    XML_LIST.sort()\n",
    "\n",
    "\n",
    "criarLista()\n",
    "#debug\n",
    "print(IMAGE_DIR)\n",
    "print(XML_DIR)\n",
    "print(IMAGE_LIST[:2])\n",
    "print(XML_LIST[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d7866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = ['../..','datasets']\n",
    "DATASET_DIR=['PKLot','UFPR05']\n",
    "\n",
    "DATASET_DIR = os.path.join(BASE_PATH[0],BASE_PATH[1],\n",
    "                           DATASET_DIR[0],DATASET_DIR[1])\n",
    "\n",
    "DADOS_DIR = os.path.join(DATASET_DIR,'output')\n",
    "X = tf.keras.preprocessing.image_dataset_from_directory(DADOS_DIR, image_size=input_shape[:2], batch_size=batch, label_mode='binary',\n",
    "                                                        shuffle=True, seed=123, color_mode='rgb', validation_split=0.3, subset = 'training')\n",
    "\n",
    "\n",
    "X_val = tf.keras.preprocessing.image_dataset_from_directory(DADOS_DIR, image_size=input_shape[:2], batch_size=batch, label_mode='binary',\n",
    "                                                        shuffle=True, seed=123, color_mode='rgb', validation_split=0.3, subset = 'validation')\n",
    "\n",
    "class_names = X.class_names\n",
    "\n",
    "\n",
    "print('\\nClasses: {} em {}'.format(X.class_names,DADOS_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30d1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(X_val)\n",
    "X_test = X_val.take(val_batches // 5)\n",
    "X_val  = X_val.skip(val_batches // 5)\n",
    "\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(X_val))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "X = X.prefetch(buffer_size=AUTOTUNE)\n",
    "X_val = X_val.prefetch(buffer_size=AUTOTUNE)\n",
    "X_test = X_test.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396675e",
   "metadata": {},
   "source": [
    "## Pre-processamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b7cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "for image, _ in X.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89334560",
   "metadata": {},
   "source": [
    "## Testando os Labels carregadas da base de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9805a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in X.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c97ee",
   "metadata": {},
   "source": [
    "### Exemplo de Imagem não segmentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615433ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sort = np.random.randint(len(IMAGE_LIST))\n",
    "\n",
    "PIL.Image.open(IMAGE_LIST[sort])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72152e16",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39310e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:45:13.507626Z",
     "iopub.status.busy": "2021-09-11T14:45:13.507374Z",
     "iopub.status.idle": "2021-09-11T14:45:13.510993Z",
     "shell.execute_reply": "2021-09-11T14:45:13.510218Z",
     "shell.execute_reply.started": "2021-09-11T14:45:13.507603Z"
    }
   },
   "source": [
    "### Normalizar as imagens para o padrão do modelo da mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07e20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305d3005",
   "metadata": {},
   "source": [
    "### Criar o modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b689716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "#base_model.summary()\n",
    "\n",
    "image_batch, label_batch = next(iter(X))\n",
    "feature_batch = base_model(image_batch)\n",
    "feature_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b5856",
   "metadata": {},
   "source": [
    "## Construindo o modelo e compilando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40657f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False) # O modelo contem uma camada de Normalização. Não destruir os pesos aprendidos\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# def modelo():\n",
    "#     model = keras.Sequential(\n",
    "#     [\n",
    "#         layers.InputLayer(input_shape),\n",
    "#         layers.Conv2D(filters=32,kernel_size=5,strides=2, activation=\"relu\"),\n",
    "#         layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=3),\n",
    "#         layers.BatchNormalization(),\n",
    "        \n",
    "#         layers.Conv2D(32,3, activation=\"relu\"),\n",
    "#         layers.Conv2D(32,3, activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(2),\n",
    "#         layers.BatchNormalization(),\n",
    "        \n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(48,activation='relu'),\n",
    "#         layers.Dropout(0.3),\n",
    "#         layers.Dense(48,activation='relu'),\n",
    "#         layers.Dropout(0.3),\n",
    "#         layers.Dense(1, activation=\"sigmoid\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "#     return model\n",
    "\n",
    "# #model = modelo()\n",
    "\n",
    "# model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# model.summary()\n",
    "# keras.utils.plot_model(model, \"./images/arquitetura.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c31aa",
   "metadata": {},
   "source": [
    "## Treinando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d2666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if flag:\n",
    "    \n",
    "    loss0, accuracy0 = model.evaluate(X_val)\n",
    "    \n",
    "    print(\"initial loss: {:.2f}\".format(loss0))\n",
    "    print(\"initial accuracy: {:.2f}\".format(accuracy0))\n",
    "    \n",
    "    history = model.fit(X, epochs=5, validation_data=X_val)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    #LOAD_DIR = os.path.split(DATASET_DIR)[0] # Separa (head,tail) -> Indice [0] = head\n",
    "    LOAD_DIR = os.path.join(DATASET_DIR,'model')\n",
    "\n",
    "    model = keras.models.load_model(LOAD_DIR)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe10aef",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd6772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if flag:\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,0.1])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025cab15",
   "metadata": {},
   "source": [
    "## Validação do modelo treinado. (testando na base de dados de validação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53fbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if flag:\n",
    "    score = model.evaluate(X_test, verbose=2)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b413aac",
   "metadata": {},
   "source": [
    "## Salvando o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59a5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if flag:\n",
    "    SAVE_DIR = os.path.split(DATASET_DIR)[0] # Separa (head,tail) -> Indice [0] = head\n",
    "    SAVE_DIR = os.path.join(DATASET_DIR,'model')\n",
    "    model.save(\n",
    "        SAVE_DIR,\n",
    "        overwrite=False,\n",
    "        include_optimizer=True,\n",
    "        save_format=None,\n",
    "        signatures=None,\n",
    "        options=None,\n",
    "        save_traces=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2faa69",
   "metadata": {},
   "source": [
    "## Validação individual (random) na base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0413e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.image_dataset_from_directory(DADOS_DIR, image_size=input_shape[:2], batch_size=batch, label_mode='binary',\n",
    "                                                        shuffle=True, seed=123, color_mode='rgb', validation_split=0.3, subset = 'training')\n",
    "\n",
    "\n",
    "X_val = tf.keras.preprocessing.image_dataset_from_directory(DADOS_DIR, image_size=input_shape[:2], batch_size=batch, label_mode='binary',\n",
    "                                                        shuffle=True, seed=123, color_mode='rgb', validation_split=0.3, subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277437d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = X.file_paths[np.random.randint(len(X.file_paths))]\n",
    "img = keras.preprocessing.image.load_img(path, target_size=input_shape[:2])\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array,  0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "score = predictions[0]\n",
    "\n",
    "print(\n",
    "    'Vaga livre: %.2f porcento.\\nVaga ocupada %.2f porcento.'\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db025e72",
   "metadata": {},
   "source": [
    "## Validação individual (random) no Banco de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5cfe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = X_val.file_paths[np.random.randint(len(X_val.file_paths))]\n",
    "img = keras.preprocessing.image.load_img(path, target_size=input_shape[:2])\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array,  0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "score = predictions[0]\n",
    "\n",
    "print(\n",
    "    'Vaga livre: %.2f porcento.\\nVaga ocupada %.2f porcento.'\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")\n",
    "\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e8c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = X_test.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "for i in range (len(predictions)):\n",
    "    #print('\\nPredictions = {}, {} = Label'.format(predictions[i].numpy(),label_batch[i].tolist()))\n",
    "    pass\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "for i in range(32):\n",
    "  ax = plt.subplot(8, 4, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba48a2",
   "metadata": {},
   "source": [
    "## CARREGANDO XML E CRIANDO OS PONTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351525ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = ET.parse(XML_LIST[0])\n",
    "root = tree.getroot()\n",
    "\n",
    "pts = np.empty(0,np.int32)\n",
    "vaga = np.empty(0,np.int32)\n",
    "\n",
    "for neighbor in root.iter('point'):\n",
    "    #print(neighbor.attrib)\n",
    "    x,y = neighbor.attrib.values()\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    a = [x,y]\n",
    "    pts = np.append(pts,[x,y])\n",
    "    \n",
    "for neighbor in root.iter('space'):\n",
    "    #print(neighbor.attrib)\n",
    "    if(len(neighbor.attrib.values())==2):\n",
    "        _,occupied = neighbor.attrib.values()\n",
    "        occupied = int(occupied)\n",
    "    if(len(neighbor.attrib.values())==1):\n",
    "        occupied=0\n",
    "        \n",
    "    vaga = np.append(vaga,occupied)\n",
    "\n",
    "#debug\n",
    "print(pts[0:4])\n",
    "print(vaga[0:40])\n",
    "\n",
    "paresXY = np.array(np.zeros((pontos,2)),np.int32) \n",
    "j=0\n",
    "for i in range(pontos):\n",
    "    paresXY[i] = pts[j:j+2]\n",
    "    j = j+2\n",
    "\n",
    "#debug\n",
    "paresXY[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4185e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop(j=0,i=0):\n",
    "    rect = cv2.boundingRect(paresXY[j:j+4])\n",
    "    x,y,w,h = rect\n",
    "    croped = im[y:y+h, x:x+w].copy()\n",
    "\n",
    "    pts = paresXY[j:j+4] - paresXY[j:j+4].min(axis=0)\n",
    "    mask = np.zeros(croped.shape[:2], croped.dtype)\n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    ## (3) do bit-op\n",
    "    dst = cv2.bitwise_and(croped, croped, mask=mask) #background preto\n",
    "\n",
    "    bg = np.ones_like(croped, np.uint8)*255\n",
    "    cv2.bitwise_not(bg,bg, mask=mask)\n",
    "    dst2 = bg+ dst #background branco\n",
    "    \n",
    "    image = cv2.resize(dst2, input_shape[:2], interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    img = image.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array,  0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "     \n",
    "    score = predictions[0]\n",
    "    score = float(score)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a482c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def juntar(im2,im,scale=80):\n",
    "    \n",
    "    img = np.hstack((im2, im))\n",
    "    \n",
    "    scale_percent = scale # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)  \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37004d6e",
   "metadata": {},
   "source": [
    "## Defina o número de Vagas (0-37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a24ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nVagas = 37\n",
    "nVagas = vagas - nVagas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f44efd0",
   "metadata": {},
   "source": [
    "## Varias imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f2561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range (1): #só repetição\n",
    "    \n",
    "    sort = np.random.randint(len(IMAGE_LIST))\n",
    "    im = cv2.imread(IMAGE_LIST[sort])\n",
    "    im2 = im.copy()\n",
    "    if im is None:\n",
    "        sys.exit(\"A imagem não foi carregada.\")\n",
    "\n",
    "    j=0\n",
    "    contador = 0\n",
    "    for i in range(nVagas,len(paresXY)//4):\n",
    "\n",
    "        score = crop(j,i)\n",
    "        #print(score)\n",
    "        if((score)<0.0):\n",
    "            cv2.polylines(im,[paresXY[j:j+4]],True,(0,255,255),2)\n",
    "            contador = contador +1\n",
    "            #print(score)\n",
    "        j=j+4\n",
    "        \n",
    "        \n",
    "\n",
    "    cv2.putText(im,str(contador),(10,700), cv2.FONT_HERSHEY_SIMPLEX, 4,(255,255,255),5,cv2.LINE_AA)\n",
    "    img_junta = juntar(im2,im,70)\n",
    "\n",
    "    cv2.imshow(IMAGE_LIST[sort], img_junta)\n",
    "    k = cv2.waitKey(3000)\n",
    "    cv2.destroyAllWindows()\n",
    "# if k == ord('q'):\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "#image = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627dc7f",
   "metadata": {},
   "source": [
    "## VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d9798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEO_FILE = os.path.join(DATASET_DIR,'pklot.mp4')\n",
    "cap = cv2.VideoCapture(VIDEO_FILE)\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print('Video não encontrado.')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, im = cap.read()\n",
    "    height, width, _ = im.shape\n",
    "    \n",
    "    if ret == True:\n",
    "    \n",
    "        j=0\n",
    "        contador = 0\n",
    "                \n",
    "    \n",
    "        for i in range(nVagas,len(paresXY)//4):\n",
    "            \n",
    "            score = crop(j,i)\n",
    "            #print(score)\n",
    "            if((score)<0.0):\n",
    "                cv2.polylines(im,[paresXY[j:j+4]],True,(0,255,255),2)\n",
    "                contador = contador +1\n",
    "                #print(score)\n",
    "            j=j+4\n",
    "        \n",
    "        cv2.putText(im,str(contador),(10,700), cv2.FONT_HERSHEY_SIMPLEX, 4,(255,255,255),5,cv2.LINE_AA)\n",
    "        cv2.imshow('Estacionamento', im)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3533aa2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-13T02:03:15.387160Z",
     "iopub.status.idle": "2021-09-13T02:03:15.387415Z",
     "shell.execute_reply": "2021-09-13T02:03:15.387309Z",
     "shell.execute_reply.started": "2021-09-13T02:03:15.387297Z"
    },
    "tags": []
   },
   "source": [
    "cap = cv2.VideoCapture('pklot.mp4')\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print('Video não encontrado.')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, im = cap.read()\n",
    "    height, width, _ = im.shape\n",
    "    \n",
    "    if ret == True:\n",
    "    \n",
    "        #j=0\n",
    "        #i=0\n",
    "        contador = 0\n",
    "                \n",
    "    \n",
    "        #for i in range(nVagas,len(paresXY)//4):\n",
    "        if i < nVagas:\n",
    "            \n",
    "            score = crop(j,i)\n",
    "            #print(score)\n",
    "            if((score)<0.0):\n",
    "                cv2.polylines(im,[paresXY[j:j+4]],True,(0,255,255),2)\n",
    "                #contador = contador +1\n",
    "                #print(score)\n",
    "            j=j+4\n",
    "            i=i+1\n",
    "        else:\n",
    "            i=0\n",
    "            j=0\n",
    "        \n",
    "        #cv2.putText(im,str(contador),(10,700), cv2.FONT_HERSHEY_SIMPLEX, 4,(255,255,255),5,cv2.LINE_AA)\n",
    "        cv2.imshow('Estacionamento', im)\n",
    "        \n",
    "        if cv2.waitKey(90) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bccfc7a",
   "metadata": {},
   "source": [
    "## Debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread(IMAGE_LIST[450])\n",
    "j=0\n",
    "contador = 0\n",
    "for i in range(nVagas,len(paresXY)//4):\n",
    "\n",
    "    score = crop(j,i)\n",
    "    #print(score)\n",
    "    if((score)<0.0):\n",
    "        cv2.polylines(im,[paresXY[j:j+4]],True,(255,255,0),2)\n",
    "        contador = contador +1\n",
    "        #print(score)\n",
    "    j=j+4\n",
    "\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "#image = plt.imread(IMAGE_LIST[350])\n",
    "#im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im)\n",
    "plt.title(IMAGE_LIST[350])\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
