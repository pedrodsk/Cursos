{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6387eac5",
   "metadata": {},
   "source": [
    "# Apêndice A."
   ]
  },
  {
   "cell_type": "raw",
   "id": "11125015",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T01:54:27.127020Z",
     "iopub.status.busy": "2021-09-13T01:54:27.126728Z",
     "iopub.status.idle": "2021-09-13T01:54:29.834077Z",
     "shell.execute_reply": "2021-09-13T01:54:29.832003Z",
     "shell.execute_reply.started": "2021-09-13T01:54:27.126987Z"
    },
    "tags": []
   },
   "source": [
    "!pip list\n",
    "!pip install opencv-python==4.4.0.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810b7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b329e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:03:52.918165Z",
     "iopub.status.busy": "2021-09-13T03:03:52.917865Z",
     "iopub.status.idle": "2021-09-13T03:03:53.482976Z",
     "shell.execute_reply": "2021-09-13T03:03:53.482348Z",
     "shell.execute_reply.started": "2021-09-13T03:03:52.918092Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- ---------\n",
      "absl-py                 0.13.0\n",
      "argon2-cffi             21.1.0\n",
      "astunparse              1.6.3\n",
      "attrs                   21.2.0\n",
      "backcall                0.2.0\n",
      "bleach                  4.1.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2021.5.30\n",
      "cffi                    1.14.6\n",
      "charset-normalizer      2.0.4\n",
      "clang                   5.0\n",
      "cycler                  0.10.0\n",
      "debugpy                 1.4.3\n",
      "decorator               5.1.0\n",
      "defusedxml              0.7.1\n",
      "entrypoints             0.3\n",
      "flatbuffers             1.12\n",
      "gast                    0.4.0\n",
      "google-auth             1.35.0\n",
      "google-auth-oauthlib    0.4.6\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.40.0\n",
      "h5py                    3.1.0\n",
      "idna                    3.2\n",
      "ipykernel               6.4.1\n",
      "ipython                 7.27.0\n",
      "ipython-genutils        0.2.0\n",
      "ipywidgets              7.6.4\n",
      "jedi                    0.18.0\n",
      "Jinja2                  3.0.1\n",
      "jsonschema              3.2.0\n",
      "jupyter                 1.0.0\n",
      "jupyter-client          7.0.2\n",
      "jupyter-console         6.4.0\n",
      "jupyter-core            4.7.1\n",
      "jupyterlab-pygments     0.1.2\n",
      "jupyterlab-widgets      1.0.1\n",
      "keras                   2.6.0\n",
      "Keras-Preprocessing     1.1.2\n",
      "kiwisolver              1.3.2\n",
      "lab                     6.4\n",
      "Markdown                3.3.4\n",
      "MarkupSafe              2.0.1\n",
      "matplotlib              3.4.3\n",
      "matplotlib-inline       0.1.3\n",
      "mistune                 0.8.4\n",
      "nbclient                0.5.4\n",
      "nbconvert               6.1.0\n",
      "nbformat                5.1.3\n",
      "nest-asyncio            1.5.1\n",
      "notebook                6.4.3\n",
      "numpy                   1.19.5\n",
      "oauthlib                3.1.1\n",
      "opencv-python           4.4.0.44\n",
      "opt-einsum              3.3.0\n",
      "packaging               21.0\n",
      "pandocfilters           1.4.3\n",
      "parso                   0.8.2\n",
      "pexpect                 4.8.0\n",
      "pickleshare             0.7.5\n",
      "Pillow                  8.3.2\n",
      "pip                     21.2.4\n",
      "prometheus-client       0.11.0\n",
      "prompt-toolkit          3.0.20\n",
      "protobuf                3.17.3\n",
      "ptyprocess              0.7.0\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycparser               2.20\n",
      "Pygments                2.10.0\n",
      "pyparsing               2.4.7\n",
      "PyQt5                   5.15.4\n",
      "PyQt5-Qt5               5.15.2\n",
      "PyQt5-sip               12.9.0\n",
      "pyrsistent              0.18.0\n",
      "python-dateutil         2.8.2\n",
      "pyzmq                   22.2.1\n",
      "qtconsole               5.1.1\n",
      "requests                2.26.0\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.7.2\n",
      "Send2Trash              1.8.0\n",
      "setuptools              56.0.0\n",
      "simplejson              3.17.5\n",
      "six                     1.15.0\n",
      "tensorboard             2.6.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.0\n",
      "tensorflow              2.6.0\n",
      "tensorflow-estimator    2.6.0\n",
      "termcolor               1.1.0\n",
      "terminado               0.12.1\n",
      "testpath                0.5.0\n",
      "tornado                 6.1\n",
      "traitlets               5.1.0\n",
      "txt2tags                3.7\n",
      "typing-extensions       3.7.4.3\n",
      "urllib3                 1.26.6\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "Werkzeug                2.0.1\n",
      "wheel                   0.37.0\n",
      "widgetsnbextension      3.5.1\n",
      "wrapt                   1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261bf46a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:03:53.484078Z",
     "iopub.status.busy": "2021-09-13T03:03:53.483866Z",
     "iopub.status.idle": "2021-09-13T03:03:53.487222Z",
     "shell.execute_reply": "2021-09-13T03:03:53.486737Z",
     "shell.execute_reply.started": "2021-09-13T03:03:53.484053Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b90a552",
   "metadata": {},
   "source": [
    "## Importações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5238c613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:03:53.489014Z",
     "iopub.status.busy": "2021-09-13T03:03:53.488630Z",
     "iopub.status.idle": "2021-09-13T03:03:54.908578Z",
     "shell.execute_reply": "2021-09-13T03:03:54.907914Z",
     "shell.execute_reply.started": "2021-09-13T03:03:53.488992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 00:03:54.905543: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-13 00:03:54.906107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-13 00:03:54.906120: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-13 00:03:54.906134: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pedro-vostro): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "flag = 1 #treinar modelo\n",
    "flag = 0 #carregar modelo !! (Comente para treinar e salvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35945ac5",
   "metadata": {},
   "source": [
    "## Configurações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c165ea9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:03:54.909648Z",
     "iopub.status.busy": "2021-09-13T03:03:54.909440Z",
     "iopub.status.idle": "2021-09-13T03:03:54.912433Z",
     "shell.execute_reply": "2021-09-13T03:03:54.912005Z",
     "shell.execute_reply.started": "2021-09-13T03:03:54.909627Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (160,160,3)\n",
    "batch = 32\n",
    "\n",
    "vagas = 40\n",
    "pontos = vagas*4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac49899",
   "metadata": {},
   "source": [
    "## Importação do Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4bb2f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:03:54.913263Z",
     "iopub.status.busy": "2021-09-13T03:03:54.913069Z",
     "iopub.status.idle": "2021-09-13T03:03:54.919196Z",
     "shell.execute_reply": "2021-09-13T03:03:54.918574Z",
     "shell.execute_reply.started": "2021-09-13T03:03:54.913244Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../datasets/PKLot/UFPR05'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = ['../..','datasets']\n",
    "DATASET_DIR=['PKLot','UFPR05']\n",
    "\n",
    "DATASET_DIR = os.path.join(BASE_PATH[0],BASE_PATH[1],\n",
    "                           DATASET_DIR[0],DATASET_DIR[1])\n",
    "DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "150f5cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:03:54.920276Z",
     "iopub.status.busy": "2021-09-13T03:03:54.919981Z",
     "iopub.status.idle": "2021-09-13T03:03:54.944827Z",
     "shell.execute_reply": "2021-09-13T03:03:54.944292Z",
     "shell.execute_reply.started": "2021-09-13T03:03:54.920249Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../datasets/PKLot/UFPR05/todas\n",
      "../../datasets/PKLot/UFPR05/todas\n",
      "['../../datasets/PKLot/UFPR05/todas/2013-02-22_06_05_00.jpg', '../../datasets/PKLot/UFPR05/todas/2013-02-22_06_10_00.jpg']\n",
      "['../../datasets/PKLot/UFPR05/todas/2013-02-22_06_05_00.xml', '../../datasets/PKLot/UFPR05/todas/2013-02-22_06_10_00.xml']\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = os.path.join(DATASET_DIR,'todas')\n",
    "XML_DIR = IMAGE_DIR\n",
    "\n",
    "\n",
    "IMAGE_LIST = []\n",
    "XML_LIST = []\n",
    "def criarLista():\n",
    "    for file in os.listdir(IMAGE_DIR):\n",
    "        if file.endswith(\".jpg\"):\n",
    "\n",
    "            file = os.path.join(IMAGE_DIR,file)\n",
    "            IMAGE_LIST.append(file)\n",
    "    IMAGE_LIST.sort()\n",
    "\n",
    "    for file in os.listdir(IMAGE_DIR):\n",
    "        if file.endswith(\".xml\"):\n",
    "\n",
    "            file = os.path.join(XML_DIR,file)\n",
    "            XML_LIST.append(file)\n",
    "    XML_LIST.sort()\n",
    "\n",
    "\n",
    "criarLista()\n",
    "#debug\n",
    "print(IMAGE_DIR)\n",
    "print(XML_DIR)\n",
    "print(IMAGE_LIST[:2])\n",
    "print(XML_LIST[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c40d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:03:54.945598Z",
     "iopub.status.busy": "2021-09-13T03:03:54.945445Z",
     "iopub.status.idle": "2021-09-13T03:04:01.889912Z",
     "shell.execute_reply": "2021-09-13T03:04:01.889272Z",
     "shell.execute_reply.started": "2021-09-13T03:03:54.945580Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 166080 files belonging to 2 classes.\n",
      "Using 116256 files for training.\n",
      "Found 166080 files belonging to 2 classes.\n",
      "Using 49824 files for validation.\n",
      "\n",
      "Classes: ['livre', 'ocupada'] em ../../datasets/PKLot/UFPR05/output\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = ['../..','datasets']\n",
    "DATASET_DIR=['PKLot','UFPR05']\n",
    "\n",
    "DATASET_DIR = os.path.join(BASE_PATH[0],BASE_PATH[1],\n",
    "                           DATASET_DIR[0],DATASET_DIR[1])\n",
    "\n",
    "DADOS_DIR = os.path.join(DATASET_DIR,'output')\n",
    "X = tf.keras.preprocessing.image_dataset_from_directory(DADOS_DIR, image_size=input_shape[:2], batch_size=batch, label_mode='binary',\n",
    "                                                        shuffle=True, seed=123, color_mode='rgb', validation_split=0.3, subset = 'training')\n",
    "\n",
    "\n",
    "X_val = tf.keras.preprocessing.image_dataset_from_directory(DADOS_DIR, image_size=input_shape[:2], batch_size=batch, label_mode='binary',\n",
    "                                                        shuffle=True, seed=123, color_mode='rgb', validation_split=0.3, subset = 'validation')\n",
    "\n",
    "class_names = X.class_names\n",
    "\n",
    "\n",
    "print('\\nClasses: {} em {}'.format(X.class_names,DADOS_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586c6045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:04:01.890865Z",
     "iopub.status.busy": "2021-09-13T03:04:01.890642Z",
     "iopub.status.idle": "2021-09-13T03:04:01.898147Z",
     "shell.execute_reply": "2021-09-13T03:04:01.897530Z",
     "shell.execute_reply.started": "2021-09-13T03:04:01.890843Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation batches: 1246\n",
      "Number of test batches: 311\n"
     ]
    }
   ],
   "source": [
    "val_batches = tf.data.experimental.cardinality(X_val)\n",
    "X_test = X_val.take(val_batches // 5)\n",
    "X_val  = X_val.skip(val_batches // 5)\n",
    "\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(X_val))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0274ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:04:01.898991Z",
     "iopub.status.busy": "2021-09-13T03:04:01.898829Z",
     "iopub.status.idle": "2021-09-13T03:04:01.904308Z",
     "shell.execute_reply": "2021-09-13T03:04:01.903433Z",
     "shell.execute_reply.started": "2021-09-13T03:04:01.898970Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "X = X.prefetch(buffer_size=AUTOTUNE)\n",
    "X_val = X_val.prefetch(buffer_size=AUTOTUNE)\n",
    "X_test = X_test.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded6e6c",
   "metadata": {},
   "source": [
    "## Pre-processamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b57b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-13T03:04:01.906007Z",
     "iopub.status.busy": "2021-09-13T03:04:01.905656Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 00:04:01.927571: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "for image, _ in X.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d732cb",
   "metadata": {},
   "source": [
    "## Testando os Labels carregadas da base de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9d66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in X.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253da9f",
   "metadata": {},
   "source": [
    "### Exemplo de Imagem não segmentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be6d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sort = np.random.randint(len(IMAGE_LIST))\n",
    "\n",
    "PIL.Image.open(IMAGE_LIST[sort])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca9d2dc",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde8a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:45:13.507626Z",
     "iopub.status.busy": "2021-09-11T14:45:13.507374Z",
     "iopub.status.idle": "2021-09-11T14:45:13.510993Z",
     "shell.execute_reply": "2021-09-11T14:45:13.510218Z",
     "shell.execute_reply.started": "2021-09-11T14:45:13.507603Z"
    }
   },
   "source": [
    "### Normalizar as imagens para o padrão do modelo da mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cd630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0d498",
   "metadata": {},
   "source": [
    "### Criar o modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df52de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "#base_model.summary()\n",
    "\n",
    "image_batch, label_batch = next(iter(X))\n",
    "feature_batch = base_model(image_batch)\n",
    "feature_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396095c",
   "metadata": {},
   "source": [
    "## Construindo o modelo e compilando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2ab5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False) # O modelo contem uma camada de Normalização. Não destruir os pesos aprendidos\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# def modelo():\n",
    "#     model = keras.Sequential(\n",
    "#     [\n",
    "#         layers.InputLayer(input_shape),\n",
    "#         layers.Conv2D(filters=32,kernel_size=5,strides=2, activation=\"relu\"),\n",
    "#         layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=3),\n",
    "#         layers.BatchNormalization(),\n",
    "        \n",
    "#         layers.Conv2D(32,3, activation=\"relu\"),\n",
    "#         layers.Conv2D(32,3, activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(2),\n",
    "#         layers.BatchNormalization(),\n",
    "        \n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(48,activation='relu'),\n",
    "#         layers.Dropout(0.3),\n",
    "#         layers.Dense(48,activation='relu'),\n",
    "#         layers.Dropout(0.3),\n",
    "#         layers.Dense(1, activation=\"sigmoid\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "#     return model\n",
    "\n",
    "# #model = modelo()\n",
    "\n",
    "# model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# model.summary()\n",
    "# keras.utils.plot_model(model, \"./images/arquitetura.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2d6ae",
   "metadata": {},
   "source": [
    "## Treinando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1cf16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if flag:\n",
    "    \n",
    "    loss0, accuracy0 = model.evaluate(X_val)\n",
    "    \n",
    "    print(\"initial loss: {:.2f}\".format(loss0))\n",
    "    print(\"initial accuracy: {:.2f}\".format(accuracy0))\n",
    "    \n",
    "    history = model.fit(X, epochs=5, validation_data=X_val)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    #LOAD_DIR = os.path.split(DATASET_DIR)[0] # Separa (head,tail) -> Indice [0] = head\n",
    "    LOAD_DIR = os.path.join(DATASET_DIR,'model')\n",
    "\n",
    "    model = keras.models.load_model(LOAD_DIR)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0541a",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feeec80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if flag:\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,0.1])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d0588e",
   "metadata": {},
   "source": [
    "## Validação do modelo treinado. (testando na base de dados de validação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f56148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if flag:\n",
    "    score = model.evaluate(X_test, verbose=2)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba9f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63024f17",
   "metadata": {},
   "source": [
    "## Salvando o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d1d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if flag:\n",
    "    SAVE_DIR = os.path.split(DATASET_DIR)[0] # Separa (head,tail) -> Indice [0] = head\n",
    "    SAVE_DIR = os.path.join(DATASET_DIR,'model')\n",
    "    model.save(\n",
    "        SAVE_DIR,\n",
    "        overwrite=False,\n",
    "        include_optimizer=True,\n",
    "        save_format=None,\n",
    "        signatures=None,\n",
    "        options=None,\n",
    "        save_traces=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a12328",
   "metadata": {},
   "source": [
    "## Validação individual (random) na base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c50b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.image_dataset_from_directory(DADOS_DIR, image_size=input_shape[:2], batch_size=batch, label_mode='binary',\n",
    "                                                        shuffle=True, seed=123, color_mode='rgb', validation_split=0.3, subset = 'training')\n",
    "\n",
    "\n",
    "X_val = tf.keras.preprocessing.image_dataset_from_directory(DADOS_DIR, image_size=input_shape[:2], batch_size=batch, label_mode='binary',\n",
    "                                                        shuffle=True, seed=123, color_mode='rgb', validation_split=0.3, subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e42ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = X.file_paths[np.random.randint(len(X.file_paths))]\n",
    "img = keras.preprocessing.image.load_img(path, target_size=input_shape[:2])\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array,  0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "score = predictions[0]\n",
    "\n",
    "print(\n",
    "    'Vaga livre: %.2f porcento.\\nVaga ocupada %.2f porcento.'\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")\n",
    "\n",
    "#plot = plt.imread(path)\n",
    "#plt.imshow(img,cmap='gray')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f7679",
   "metadata": {},
   "source": [
    "## Validação individual (random) no Banco de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc46365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = X_val.file_paths[np.random.randint(len(X_val.file_paths))]\n",
    "img = keras.preprocessing.image.load_img(path, target_size=input_shape[:2])\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array,  0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "#predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "score = predictions[0]\n",
    "\n",
    "print(\n",
    "    'Vaga livre: %.2f porcento.\\nVaga ocupada %.2f porcento.'\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")\n",
    "\n",
    "#plot = plt.imread(path)\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8498b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = X_test.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "for i in range (len(predictions)):\n",
    "    print('\\nPredictions = {}, {} = Label'.format(predictions[i].numpy(),label_batch[i].tolist()))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "for i in range(32):\n",
    "  ax = plt.subplot(8, 4, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2aef9",
   "metadata": {},
   "source": [
    "## CARREGANDO XML E CRIANDO OS PONTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097908c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = ET.parse(XML_LIST[0])\n",
    "root = tree.getroot()\n",
    "\n",
    "pts = np.empty(0,np.int32)\n",
    "vaga = np.empty(0,np.int32)\n",
    "\n",
    "for neighbor in root.iter('point'):\n",
    "    #print(neighbor.attrib)\n",
    "    x,y = neighbor.attrib.values()\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    a = [x,y]\n",
    "    pts = np.append(pts,[x,y])\n",
    "    \n",
    "for neighbor in root.iter('space'):\n",
    "    #print(neighbor.attrib)\n",
    "    if(len(neighbor.attrib.values())==2):\n",
    "        _,occupied = neighbor.attrib.values()\n",
    "        occupied = int(occupied)\n",
    "    if(len(neighbor.attrib.values())==1):\n",
    "        occupied=0\n",
    "        \n",
    "    vaga = np.append(vaga,occupied)\n",
    "\n",
    "#debug\n",
    "print(pts[0:4])\n",
    "print(vaga[0:40])\n",
    "\n",
    "paresXY = np.array(np.zeros((pontos,2)),np.int32) \n",
    "j=0\n",
    "for i in range(pontos):\n",
    "    paresXY[i] = pts[j:j+2]\n",
    "    j = j+2\n",
    "\n",
    "#debug\n",
    "paresXY[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba2254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop(j=0,i=0):\n",
    "    rect = cv2.boundingRect(paresXY[j:j+4])\n",
    "    x,y,w,h = rect\n",
    "    croped = im[y:y+h, x:x+w].copy()\n",
    "\n",
    "    pts = paresXY[j:j+4] - paresXY[j:j+4].min(axis=0)\n",
    "    mask = np.zeros(croped.shape[:2], croped.dtype)\n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    ## (3) do bit-op\n",
    "    dst = cv2.bitwise_and(croped, croped, mask=mask) #background preto\n",
    "\n",
    "    bg = np.ones_like(croped, np.uint8)*255\n",
    "    cv2.bitwise_not(bg,bg, mask=mask)\n",
    "    dst2 = bg+ dst #background branco\n",
    "    \n",
    "    image = cv2.resize(dst2, input_shape[:2], interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    img = image.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array,  0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "     \n",
    "    score = predictions[0]\n",
    "    score = float(score)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424f916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def juntar(im2,im,scale=80):\n",
    "    \n",
    "    img = np.hstack((im2, im))\n",
    "    \n",
    "    scale_percent = scale # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)  \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2b18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nVagas = 3\n",
    "nVagas = vagas - nVagas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f7acc",
   "metadata": {},
   "source": [
    "## Varias imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe6d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3c125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff22ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range (1): #só repetição\n",
    "    \n",
    "    sort = np.random.randint(len(IMAGE_LIST))\n",
    "    im = cv2.imread(IMAGE_LIST[sort])\n",
    "    im2 = im.copy()\n",
    "    if im is None:\n",
    "        sys.exit(\"A imagem não foi carregada.\")\n",
    "\n",
    "    j=0\n",
    "    contador = 0\n",
    "    for i in range(nVagas,len(paresXY)//4):\n",
    "\n",
    "        score = crop(j,i)\n",
    "        #print(score)\n",
    "        if((score)<0.0):\n",
    "            cv2.polylines(im,[paresXY[j:j+4]],True,(0,255,255),2)\n",
    "            contador = contador +1\n",
    "            #print(score)\n",
    "        j=j+4\n",
    "        \n",
    "        \n",
    "\n",
    "    cv2.putText(im,str(contador),(10,700), cv2.FONT_HERSHEY_SIMPLEX, 4,(255,255,255),5,cv2.LINE_AA)\n",
    "    img_junta = juntar(im2,im,70)\n",
    "\n",
    "    cv2.imshow(IMAGE_LIST[sort], img_junta)\n",
    "    k = cv2.waitKey(3000)\n",
    "    cv2.destroyAllWindows()\n",
    "# if k == ord('q'):\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "#image = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafe218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d417666",
   "metadata": {},
   "source": [
    "## Única Imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = np.random.randint(len(IMAGE_LIST))\n",
    "im = cv2.imread(IMAGE_LIST[350])\n",
    "im2 = im.copy()\n",
    "if im is None:\n",
    "    sys.exit(\"A imagem não foi carregada.\")\n",
    "\n",
    "j=0\n",
    "contador = 0\n",
    "for i in range(nVagas,len(paresXY)//4):\n",
    "\n",
    "    score = crop(j,i)\n",
    "    #print(score)\n",
    "    if((score)<0.0):\n",
    "        cv2.polylines(im,[paresXY[j:j+4]],True,(0,255,255),2)\n",
    "        contador = contador +1\n",
    "        #print(score)\n",
    "    j=j+4\n",
    "\n",
    "\n",
    "\n",
    "cv2.putText(im,str(contador),(10,700), cv2.FONT_HERSHEY_SIMPLEX, 4,(255,255,255),5,cv2.LINE_AA)\n",
    "img_junta = juntar(im2,im,70)\n",
    "\n",
    "cv2.imshow(IMAGE_LIST[sort], im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#image = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb6526",
   "metadata": {},
   "source": [
    "## VIDEO"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4a9879f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-13T02:03:15.386148Z",
     "iopub.status.idle": "2021-09-13T02:03:15.386386Z",
     "shell.execute_reply": "2021-09-13T02:03:15.386285Z",
     "shell.execute_reply.started": "2021-09-13T02:03:15.386273Z"
    },
    "tags": []
   },
   "source": [
    "cap = cv2.VideoCapture('pklot.mp4')\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print('Video não encontrado.')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, im = cap.read()\n",
    "    height, width, _ = im.shape\n",
    "    \n",
    "    if ret == True:\n",
    "    \n",
    "        j=0\n",
    "        contador = 0\n",
    "                \n",
    "    \n",
    "        for i in range(nVagas,len(paresXY)//4):\n",
    "            \n",
    "            score = crop(j,i)\n",
    "            #print(score)\n",
    "            if((score)<0.0):\n",
    "                cv2.polylines(im,[paresXY[j:j+4]],True,(0,255,255),2)\n",
    "                contador = contador +1\n",
    "                #print(score)\n",
    "            j=j+4\n",
    "        \n",
    "        cv2.putText(im,str(contador),(10,700), cv2.FONT_HERSHEY_SIMPLEX, 4,(255,255,255),5,cv2.LINE_AA)\n",
    "        cv2.imshow('Estacionamento', im)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad7114b4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-13T02:03:15.387160Z",
     "iopub.status.idle": "2021-09-13T02:03:15.387415Z",
     "shell.execute_reply": "2021-09-13T02:03:15.387309Z",
     "shell.execute_reply.started": "2021-09-13T02:03:15.387297Z"
    },
    "tags": []
   },
   "source": [
    "cap = cv2.VideoCapture('pklot.mp4')\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print('Video não encontrado.')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, im = cap.read()\n",
    "    height, width, _ = im.shape\n",
    "    \n",
    "    if ret == True:\n",
    "    \n",
    "        #j=0\n",
    "        #i=0\n",
    "        contador = 0\n",
    "                \n",
    "    \n",
    "        #for i in range(nVagas,len(paresXY)//4):\n",
    "        if i < nVagas:\n",
    "            \n",
    "            score = crop(j,i)\n",
    "            #print(score)\n",
    "            if((score)<0.0):\n",
    "                cv2.polylines(im,[paresXY[j:j+4]],True,(0,255,255),2)\n",
    "                #contador = contador +1\n",
    "                #print(score)\n",
    "            j=j+4\n",
    "            i=i+1\n",
    "        else:\n",
    "            i=0\n",
    "            j=0\n",
    "        \n",
    "        #cv2.putText(im,str(contador),(10,700), cv2.FONT_HERSHEY_SIMPLEX, 4,(255,255,255),5,cv2.LINE_AA)\n",
    "        cv2.imshow('Estacionamento', im)\n",
    "        \n",
    "        if cv2.waitKey(90) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50035684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d10f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "123bed5d",
   "metadata": {},
   "source": [
    "## Debug "
   ]
  },
  {
   "cell_type": "raw",
   "id": "69c42254",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-13T02:03:15.389116Z",
     "iopub.status.idle": "2021-09-13T02:03:15.389365Z",
     "shell.execute_reply": "2021-09-13T02:03:15.389256Z",
     "shell.execute_reply.started": "2021-09-13T02:03:15.389244Z"
    }
   },
   "source": [
    "im = plt.imread(IMAGE_LIST[450])\n",
    "j=0\n",
    "contador = 0\n",
    "for i in range(len(paresXY)//4):\n",
    "\n",
    "    score = crop(j,i)\n",
    "    #print(score)\n",
    "    if((score)<0.0):\n",
    "        cv2.polylines(im,[paresXY[j:j+4]],True,(255,255,0),2)\n",
    "        contador = contador +1\n",
    "        #print(score)\n",
    "    j=j+4\n",
    "\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "#image = plt.imread(IMAGE_LIST[350])\n",
    "#im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im)\n",
    "plt.title(IMAGE_LIST[350])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e5231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971982f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc1aae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f297d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d92dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7de4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bdd166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a8f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609baf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cde257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864ea4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8ae4b327",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-13T02:03:15.399753Z",
     "iopub.status.idle": "2021-09-13T02:03:15.400113Z",
     "shell.execute_reply": "2021-09-13T02:03:15.400004Z",
     "shell.execute_reply.started": "2021-09-13T02:03:15.399991Z"
    }
   },
   "source": [
    "from threading import Thread\n",
    "import cv2\n",
    "\n",
    "class VideoGet:\n",
    "    \"\"\"\n",
    "    Class that continuously gets frames from a VideoCapture object\n",
    "    with a dedicated thread.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "    \n",
    "    def start(self):\n",
    "        Thread(target=self.get, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def get(self):\n",
    "        while not self.stopped:\n",
    "            if not self.grabbed:\n",
    "                self.stop()\n",
    "            else:\n",
    "                (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        \n",
    "    def threadVideoGet(source=0):\n",
    "        \"\"\"\n",
    "        Dedicated thread for grabbing video frames with VideoGet object.\n",
    "        Main thread shows video frames.\n",
    "        \"\"\"\n",
    "\n",
    "        video_getter = VideoGet(source).start()\n",
    "        cps = CountsPerSec().start()\n",
    "\n",
    "        while True:\n",
    "            if (cv2.waitKey(1) == ord(\"q\")) or video_getter.stopped:\n",
    "                video_getter.stop()\n",
    "                break\n",
    "\n",
    "            frame = video_getter.frame\n",
    "            frame = putIterationsPerSec(frame, cps.countsPerSec())\n",
    "            cv2.imshow(\"Video\", frame)\n",
    "            cps.increment()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ee3faa4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-13T02:03:15.400751Z",
     "iopub.status.idle": "2021-09-13T02:03:15.401009Z",
     "shell.execute_reply": "2021-09-13T02:03:15.400905Z",
     "shell.execute_reply.started": "2021-09-13T02:03:15.400893Z"
    }
   },
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from collections import deque\n",
    "\n",
    "from common import clock, draw_str, StatValue\n",
    "import video\n",
    "\n",
    "\n",
    "class DummyTask:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def ready(self):\n",
    "        return True\n",
    "    def get(self):\n",
    "        return self.data\n",
    "\n",
    "def main():\n",
    "    import sys\n",
    "\n",
    "    try:\n",
    "        fn = sys.argv[1]\n",
    "    except:\n",
    "        fn = 0\n",
    "    cap = video.create_capture(fn)\n",
    "\n",
    "\n",
    "    def process_frame(frame, t0):\n",
    "        # some intensive computation...\n",
    "        frame = cv2.medianBlur(frame, 19)\n",
    "        frame = cv2.medianBlur(frame, 19)\n",
    "        return frame, t0\n",
    "\n",
    "    threadn = cv2.getNumberOfCPUs()\n",
    "    pool = ThreadPool(processes = threadn)\n",
    "    pending = deque()\n",
    "\n",
    "    threaded_mode = True\n",
    "\n",
    "    latency = StatValue()\n",
    "    frame_interval = StatValue()\n",
    "    last_frame_time = clock()\n",
    "    while True:\n",
    "        while len(pending) > 0 and pending[0].ready():\n",
    "            res, t0 = pending.popleft().get()\n",
    "            latency.update(clock() - t0)\n",
    "            draw_str(res, (20, 20), \"threaded      :  \" + str(threaded_mode))\n",
    "            draw_str(res, (20, 40), \"latency        :  %.1f ms\" % (latency.value*1000))\n",
    "            draw_str(res, (20, 60), \"frame interval :  %.1f ms\" % (frame_interval.value*1000))\n",
    "            cv2.imshow('threaded video', res)\n",
    "        if len(pending) < threadn:\n",
    "            _ret, frame = cap.read()\n",
    "            t = clock()\n",
    "            frame_interval.update(t - last_frame_time)\n",
    "            last_frame_time = t\n",
    "            if threaded_mode:\n",
    "                task = pool.apply_async(process_frame, (frame.copy(), t))\n",
    "            else:\n",
    "                task = DummyTask(process_frame(frame, t))\n",
    "            pending.append(task)\n",
    "        ch = cv2.waitKey(1)\n",
    "        if ch == ord(' '):\n",
    "            threaded_mode = not threaded_mode\n",
    "        if ch == 27:\n",
    "            break\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(__doc__)\n",
    "    main()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d863ea39",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-13T02:03:15.401824Z",
     "iopub.status.idle": "2021-09-13T02:03:15.402095Z",
     "shell.execute_reply": "2021-09-13T02:03:15.401982Z",
     "shell.execute_reply.started": "2021-09-13T02:03:15.401969Z"
    }
   },
   "source": [
    "import cv2\n",
    "import multiprocessing as mp\n",
    "\n",
    "def getFrame(queue, startFrame, endFrame):\n",
    "    cap = cv2.VideoCapture(file)  # crashes here\n",
    "    print(\"opened capture {}\".format(mp.current_process()))\n",
    "    for frame in range(startFrame, endFrame):\n",
    "        # cap.set(cv2.CAP_PROP_POS_FRAMES, frame)  # opencv3            \n",
    "        cap.set(cv2.CV_CAP_PROP_POS_FRAMES, frame)\n",
    "        # frameNo = int(cap.get(cv2.CAP_PROP_POS_FRAMES))  # opencv3\n",
    "        frameNo = int(cap.get(cv2.CV_CAP_PROP_POS_FRAMES))\n",
    "        ret, f = cap.read()\n",
    "        if ret:\n",
    "            print(\"{} - put ({})\".format(mp.current_process(), frameNo))\n",
    "            queue.put((frameNo, f))\n",
    "    cap.release()\n",
    "\n",
    "file = \"video.mov\"\n",
    "capture_temp = cv2.VideoCapture(file)\n",
    "fileLen = int((capture_temp).get(cv2.CAP_PROP_FRAME_COUNT))  # opencv3\n",
    "#fileLen = int((capture_temp).get(cv2.CV_CAP_PROP_FRAME_COUNT))\n",
    "capture_temp.release()\n",
    "\n",
    "# get cpuCount for processCount\n",
    "# processCount = mp.cpu_count() / 3\n",
    "processCount = 2\n",
    "\n",
    "inQ1 = mp.JoinableQueue()  # not sure if this is right queue type, but I also tried mp.Queue()\n",
    "inQ2 = mp.JoinableQueue()\n",
    "qList = [inQ1, inQ2]\n",
    "\n",
    "# set up bunches\n",
    "bunches = []\n",
    "for startFrame in range(0,fileLen, int(fileLen / processCount)):\n",
    "    endFrame = startFrame + int(fileLen / processCount)\n",
    "    bunches.append((startFrame, endFrame))\n",
    "\n",
    "getFrames = []\n",
    "for i in range(processCount):\n",
    "    getFrames.append(mp.Process(target=getFrame, args=(qList[i], bunches[i][0], bunches[i][1])))\n",
    "\n",
    "for process in getFrames:\n",
    "    process.start()\n",
    "\n",
    "results1 = [inQ1.get() for p in range(bunches[0][0], bunches[0][1])]\n",
    "results2 = [inQ2.get() for p in range(bunches[1][0], bunches[1][1])]\n",
    "\n",
    "inQ1.close()\n",
    "inQ2.close()\n",
    "\n",
    "for process in getFrames:\n",
    "    process.terminate()\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "adsasad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b0002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c96488-0a08-4d7c-a25a-8880ff023363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python==4.4.0.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71993eac-4b74-4d9b-8050-21754cf69b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall PyQt5 PyQt5-Qt5 PyQt5-sip opencv-python -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0af20-0237-42bf-a3de-9e8afeac51ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall QtPy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1d938-95f1-411e-ac2c-6ca8ed755ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03baedd4-5272-46c3-9004-fcdee3bf2207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install PyQt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe39bc-7bb0-43fb-bce0-0ddfab63a144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --no-binary opencv-python opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e4b6b-9029-42c1-a127-1047df4386ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tccpedro",
   "language": "python",
   "name": "tccpedro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
